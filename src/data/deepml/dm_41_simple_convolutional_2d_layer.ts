import { Problem } from '../../types';

export const DM_41_SIMPLE_CONVOLUTIONAL_2D_LAYER: Problem = {
  "id": "dm_41_title_in_snake_case",
  "title": "Simple Convolutional 2D Layer",
  "difficulty": "Medium",
  "tags": [
    "CNNs",
    "Neural Networks",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Implement a function that performs a 2D convolution (cross-correlation as used in deep learning) over a single-channel 2D input matrix with a given 2D kernel, zero-padding, and stride.\n\nGiven:\n- input_matrix: 2D matrix (H \u00d7 W)\n- kernel: 2D convolution kernel (kH \u00d7 kW)\n- padding: integer number of zero-padding pixels added to all sides\n- stride: integer step size for the sliding window\n\nThe function should return the output matrix of the convolution.\n\nExample:\n\n```python\ninput_matrix = [\n    [1, 2, 3, 4],\n    [5, 6, 7, 8],\n    [9, 10, 11, 12],\n    [13, 14, 15, 16]\n]\n\nkernel = [\n    [1, 0],\n    [-1, 1]\n]\n\npadding = 1\nstride = 2\n\n# Expected output\n# [[ 1.,  1., -4.],\n#  [ 9.,  7., -4.],\n#  [ 0., 14., 16.]]\n```\n\nNotes:\n- Use zero-padding.\n- Use cross-correlation (do not flip the kernel).\n- Output shape should be computed as: out_h = floor((H + 2P \u2212 kH) / S) + 1 and out_w = floor((W + 2P \u2212 kW) / S) + 1.",
  "solutionExplanation": "A 2D convolution in deep learning frameworks is typically implemented as cross-correlation: the kernel is slid over the input without flipping, and at each location the elementwise product between the kernel and the corresponding input patch is summed. With zero-padding P, the input is conceptually extended on all sides with P zeros. Stride S determines how far the kernel moves between successive positions. The output spatial dimensions are computed as out_h = floor((H + 2P \u2212 kH) / S) + 1 and out_w = floor((W + 2P \u2212 kW) / S) + 1.\n\nTo implement this efficiently in PyTorch, we can treat the 2D input as a 4D tensor with shape [N=1, C=1, H, W] and use torch.nn.functional.unfold to extract all sliding local blocks (taking into account padding and stride). Each local block is a column in the unfolded tensor. We then flatten the kernel and perform a batched dot product with these columns to obtain the output values, and finally reshape the result to [out_h, out_w]. This approach is vectorized and avoids explicit Python loops over spatial locations, matching the expected cross-correlation behavior and the example output.",
  "solutionCode": "import torch\nimport torch.nn.functional as F\n\ndef simple_conv2d(input_matrix: torch.Tensor, kernel: torch.Tensor, padding: int, stride: int) -> torch.Tensor:\n    \"\"\"\n    Perform a 2D cross-correlation (DL-style convolution) on a single-channel 2D input.\n\n    Args:\n        input_matrix: 2D tensor of shape (H, W).\n        kernel: 2D tensor of shape (kH, kW).\n        padding: int, zero-padding on all sides.\n        stride: int, stride for the sliding window.\n\n    Returns:\n        2D tensor of shape (out_h, out_w) with the convolution result.\n    \"\"\"\n    if input_matrix.dim() != 2 or kernel.dim() != 2:\n        raise ValueError(\"input_matrix and kernel must be 2D tensors.\")\n\n    # Ensure floating point for accumulation\n    x = input_matrix.to(dtype=torch.get_default_dtype())\n    k = kernel.to(dtype=torch.get_default_dtype())\n\n    H, W = x.shape\n    kH, kW = k.shape\n\n    if kH <= 0 or kW <= 0:\n        raise ValueError(\"Kernel must have positive spatial dimensions.\")\n    if padding < 0 or stride <= 0:\n        raise ValueError(\"Padding must be >= 0 and stride must be > 0.\")\n\n    # Compute output spatial dimensions\n    out_h = (H + 2 * padding - kH) // stride + 1\n    out_w = (W + 2 * padding - kW) // stride + 1\n    if out_h <= 0 or out_w <= 0:\n        raise ValueError(\"Non-positive output size. Check kernel, padding, and stride.\")\n\n    # Prepare input as NCHW\n    x_nchw = x.unsqueeze(0).unsqueeze(0)  # [1, 1, H, W]\n\n    # Extract patches with unfold: shape [1, kH*kW, L]\n    patches = F.unfold(x_nchw, kernel_size=(kH, kW), padding=padding, stride=stride)\n\n    # Flatten kernel to shape [kH*kW, 1] (broadcastable)\n    k_flat = k.reshape(-1, 1)  # [kH*kW, 1]\n\n    # Compute dot product per patch (cross-correlation)\n    # patches: [1, kH*kW, L], k_flat: [kH*kW, 1] -> multiply and sum over dim=1\n    out_cols = (patches * k_flat.unsqueeze(0)).sum(dim=1)  # [1, L]\n\n    # Reshape to (out_h, out_w)\n    out = out_cols.view(out_h, out_w)\n    return out\n\n# Example usage\nif __name__ == \"__main__\":\n    input_matrix = torch.tensor([\n        [1, 2, 3, 4],\n        [5, 6, 7, 8],\n        [9, 10, 11, 12],\n        [13, 14, 15, 16]\n    ], dtype=torch.float32)\n\n    kernel = torch.tensor([\n        [1, 0],\n        [-1, 1]\n    ], dtype=torch.float32)\n\n    padding = 1\n    stride = 2\n\n    output = simple_conv2d(input_matrix, kernel, padding, stride)\n    print(output)\n    # Expected:\n    # tensor([[ 1.,  1., -4.],\n    #         [ 9.,  7., -4.],\n    #         [ 0., 14., 16.]])\n",
  "timeComplexity": "O(H_out * W_out * K_h * K_w)",
  "spaceComplexity": "O(H_out * W_out) for the output; O(H_out * W_out * K_h * K_w) transient auxiliary memory due to unfolding",
  "platform": "deepml"
};
