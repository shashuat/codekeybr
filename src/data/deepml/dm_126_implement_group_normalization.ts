import { Problem } from '../../types';

export const DM_126_IMPLEMENT_GROUP_NORMALIZATION: Problem = {
  "id": "dm_126_implement_group_normalization",
  "title": "Implement Group Normalization",
  "difficulty": "Medium",
  "tags": [
    "Neural Networks",
    "Regularization",
    "CNNs"
  ],
  "descriptionMarkdown": "Write a Python function to perform Group Normalization on a 4D input tensor with shape (B, C, H, W). The function should normalize over smaller groups of channels, then apply a learned scale (gamma) and shift (beta).\n\nExample:\n- Input: X.shape = (2, 2, 2, 2), gamma = [1, 1], beta = [0, 0], num_groups = 2\n- Output: A tensor where each group of channels is independently normalized, then scaled by gamma and shifted by beta.\n\nReasoning:\n1. Split the channels into `num_groups` groups.\n2. Compute mean and variance per group over the grouped channels and spatial dimensions (H, W).\n3. Normalize within each group.\n4. Scale and shift the normalized tensor with per-channel gamma and beta.",
  "solutionExplanation": "Group Normalization (GN) normalizes features by dividing channels into G groups and computing statistics within each group. Given an input X of shape (B, C, H, W), we reshape it to (B, G, C/G, H, W), compute the mean and variance over the last three dimensions (the channels within the group and spatial dimensions), and then normalize using these statistics. This removes dependency on the batch size and is effective when batch sizes are small.\n\nAfter normalization, we apply a learned per-channel affine transform with gamma (scale) and beta (shift). Practically, gamma and beta are shaped or broadcast to (1, C, 1, 1) to match X and applied elementwise. We include a small epsilon for numerical stability and use unbiased=False for variance to match common deep learning implementations.",
  "solutionCode": "import torch\nfrom typing import Tuple\n\n\ndef group_normalization(\n    X: torch.Tensor,\n    gamma: torch.Tensor,\n    beta: torch.Tensor,\n    num_groups: int,\n    eps: float = 1e-5,\n) -> torch.Tensor:\n    \"\"\"\n    Perform Group Normalization on a 4D tensor.\n\n    Args:\n        X: Input tensor of shape (B, C, H, W).\n        gamma: Scale parameter, shape (C,) or broadcastable to (1, C, 1, 1).\n        beta: Shift parameter, shape (C,) or broadcastable to (1, C, 1, 1).\n        num_groups: Number of groups to divide channels into (must divide C).\n        eps: Small constant for numerical stability.\n\n    Returns:\n        Normalized tensor of shape (B, C, H, W).\n    \"\"\"\n    if X.dim() != 4:\n        raise ValueError(f\"X must be 4D (B, C, H, W), got shape {tuple(X.shape)}\")\n\n    B, C, H, W = X.shape\n    if C % num_groups != 0:\n        raise ValueError(\n            f\"num_groups ({num_groups}) must divide number of channels C ({C}).\"\n        )\n\n    # Ensure gamma and beta are per-channel and on the correct device/dtype\n    def _prep_param(p: torch.Tensor, name: str) -> torch.Tensor:\n        if p.dim() == 1:\n            if p.numel() != C:\n                raise ValueError(f\"{name} must have length C={C}, got {p.numel()}.\")\n            p = p.view(1, C, 1, 1)\n        else:\n            # Try to reshape if it's (C,1,1) or already (1,C,1,1)\n            if p.shape == (C, 1, 1):\n                p = p.view(1, C, 1, 1)\n            elif p.shape != (1, C, 1, 1):\n                # Let broadcasting attempt fail later with a clearer message\n                pass\n        return p.to(device=X.device, dtype=X.dtype)\n\n    gamma = _prep_param(gamma, \"gamma\")\n    beta = _prep_param(beta, \"beta\")\n\n    G = num_groups\n    # Reshape to group channels: (B, G, C//G, H, W)\n    Xg = X.view(B, G, C // G, H, W)\n\n    # Compute per-group mean and variance across (channels_in_group, H, W)\n    mean = Xg.mean(dim=(2, 3, 4), keepdim=True)\n    var = Xg.var(dim=(2, 3, 4), unbiased=False, keepdim=True)\n\n    # Normalize\n    Xg_norm = (Xg - mean) / torch.sqrt(var + eps)\n\n    # Restore shape to (B, C, H, W)\n    X_norm = Xg_norm.view(B, C, H, W)\n\n    # Apply per-channel affine transform\n    Y = X_norm * gamma + beta\n    return Y\n\n\n# Example usage\nif __name__ == \"__main__\":\n    # Example: X.shape = (2, 2, 2, 2), gamma = [1, 1], beta = [0, 0], num_groups = 2\n    X = torch.tensor(\n        [\n            [\n                [[1.0, 2.0], [3.0, 4.0]],  # channel 0\n                [[5.0, 6.0], [7.0, 8.0]],  # channel 1\n            ],\n            [\n                [[2.0, 3.0], [4.0, 5.0]],\n                [[6.0, 7.0], [8.0, 9.0]],\n            ],\n        ]\n    )  # shape (2, 2, 2, 2)\n    gamma = torch.tensor([1.0, 1.0])\n    beta = torch.tensor([0.0, 0.0])\n\n    out = group_normalization(X, gamma, beta, num_groups=2)\n    print(\"Output shape:\", out.shape)\n    print(out)\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
