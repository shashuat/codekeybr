import { Problem } from '../../types';

export const DM_95_CALCULATE_THE_PHI_COEFFICIENT: Problem = {
  "id": "dm_95_calculate_the_phi_coefficient",
  "title": "Calculate the Phi Coefficient",
  "difficulty": "Easy",
  "tags": [
    "Probability"
  ],
  "descriptionMarkdown": "Implement a function to calculate the Phi coefficient, a measure of the correlation between two binary variables. The function should take two lists of integers (0s and 1s) as input and return the Phi coefficient rounded to 4 decimal places.\n\nExample:\n- Input: `phi_corr([1, 1, 0, 0], [0, 0, 1, 1])`\n- Output: `-1.0`\n\nThe Phi coefficient measures the correlation between two binary variables. In the example, the variables have a perfect negative correlation, resulting in a Phi coefficient of -1.0.",
  "solutionExplanation": "The Phi coefficient is the Pearson correlation coefficient applied to two binary variables. It can be computed from the 2x2 contingency table of counts: n11 (x=1,y=1), n10 (x=1,y=0), n01 (x=0,y=1), and n00 (x=0,y=0). The formula is:\n\nphi = (n11*n00 - n10*n01) / sqrt((n1.)*(n0.)*(n.1)*(n.0))\n\nwhere n1. = n10 + n11, n0. = n00 + n01, n.1 = n01 + n11, and n.0 = n00 + n10. This formulation is efficient because it only requires a single pass to compute the four counts.\n\nIf the denominator is zero (which happens when one or both variables are constant), the correlation is undefined; a practical choice is to return 0.0 to indicate no measurable association. The final value is rounded to 4 decimal places as required.",
  "solutionCode": "import torch\nfrom typing import List\n\n\ndef phi_corr(x: List[int], y: List[int]) -> float:\n    \"\"\"\n    Calculate the Phi coefficient between two binary variables using PyTorch.\n\n    Args:\n        x: List of 0/1 integers\n        y: List of 0/1 integers\n\n    Returns:\n        float: Phi coefficient rounded to 4 decimal places.\n    \"\"\"\n    # Basic validations\n    if len(x) != len(y):\n        raise ValueError(\"Inputs x and y must have the same length.\")\n    if len(x) == 0:\n        raise ValueError(\"Inputs must be non-empty.\")\n\n    tx = torch.as_tensor(x, dtype=torch.int64)\n    ty = torch.as_tensor(y, dtype=torch.int64)\n\n    # Validate binary inputs (only 0 or 1)\n    if not (torch.all((tx == 0) | (tx == 1)) and torch.all((ty == 0) | (ty == 1))):\n        raise ValueError(\"Inputs must contain only 0s and 1s.\")\n\n    # Convert to boolean tensors for efficient logical ops\n    xb = tx.bool()\n    yb = ty.bool()\n\n    # Confusion matrix counts\n    n11 = (xb & yb).sum().item()\n    n10 = (xb & (~yb)).sum().item()\n    n01 = ((~xb) & yb).sum().item()\n    n00 = ((~xb) & (~yb)).sum().item()\n\n    # Numerator and denominator (as torch tensors for consistency)\n    num = torch.tensor(n11 * n00 - n10 * n01, dtype=torch.float64)\n    n1_ = n10 + n11\n    n0_ = n00 + n01\n    n_1 = n01 + n11\n    n_0 = n00 + n10\n    denom = torch.sqrt(torch.tensor(n1_ * n0_ * n_1 * n_0, dtype=torch.float64))\n\n    # Handle zero denominator (undefined correlation); return 0.0 as a safe default\n    if denom.item() == 0.0:\n        phi = torch.tensor(0.0, dtype=torch.float64)\n    else:\n        phi = num / denom\n\n    return round(float(phi.item()), 4)\n\n\ndef solution():\n    # Example usage\n    example_x = [1, 1, 0, 0]\n    example_y = [0, 0, 1, 1]\n    return phi_corr(example_x, example_y)\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
