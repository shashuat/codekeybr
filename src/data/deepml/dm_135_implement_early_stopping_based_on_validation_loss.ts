import { Problem } from '../../types';

export const DM_135_IMPLEMENT_EARLY_STOPPING_BASED_ON_VALIDATION_LOSS: Problem = {
  "id": "dm_135_implement_early_stopping_based_on_validation_loss",
  "title": "Implement Early Stopping Based on Validation Loss",
  "difficulty": "Easy",
  "tags": [
    "Optimization",
    "Regularization",
    "Loss Functions"
  ],
  "descriptionMarkdown": "Create a function to decide when to stop training a model early based on a list of validation losses. The early stopping criterion should stop training if the validation loss hasn't improved for a specified number of epochs (patience), and only count as improvement if the loss decreases by more than a certain threshold (min_delta). Your function should return a tuple: (stop_epoch, best_epoch), where an improvement is recorded only when the loss decreases by more than min_delta from the previous best.\n\nExample:\n- Input: [0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78], patience=2, min_delta=0.01\n- Output: (4, 2)\n\nReasoning: The best validation loss is 0.75 at epoch 2. There is no improvement greater than 0.01 for the next 2 epochs. Therefore, training should stop at epoch 4.",
  "solutionExplanation": "The key idea of early stopping is to monitor a validation metric (here, validation loss) and halt training when the model stops improving. We track the best observed validation loss and a counter of consecutive epochs without sufficient improvement. An improvement is considered valid only if the new loss decreases by strictly more than min_delta relative to the current best loss. When the count of consecutive non-improving epochs reaches the patience threshold, we stop.\n\nTo implement this, we iterate over the validation losses sequentially. We initialize the best loss and best epoch using the first value. For each subsequent epoch, if the loss improves by more than min_delta, we update the best loss/epoch and reset the wait counter. Otherwise, we increment the wait counter. When wait >= patience, we stop and return the current epoch index as stop_epoch along with best_epoch. If early stopping never triggers within the provided sequence, we return the last epoch index and the best epoch found. Epoch indices are 0-based to match the example.",
  "solutionCode": "import torch\nimport torch.nn as nn\nfrom typing import Tuple, Union, Sequence\n\ndef early_stopping(val_losses: Union[Sequence[float], torch.Tensor], patience: int, min_delta: float) -> Tuple[int, int]:\n    \"\"\"\n    Determine early stopping epoch based on validation losses.\n\n    Args:\n        val_losses: Sequence or tensor of validation losses per epoch (0-based indexing).\n        patience: Number of consecutive epochs allowed without sufficient improvement.\n        min_delta: Minimum required decrease in loss to qualify as an improvement.\n\n    Returns:\n        (stop_epoch, best_epoch): Both are 0-based indices. If early stopping does not\n        trigger within the provided series, stop_epoch equals the last index.\n\n    Raises:\n        ValueError: If val_losses is empty or patience < 1.\n    \"\"\"\n    losses = torch.as_tensor(val_losses, dtype=torch.float32)\n    if losses.numel() == 0:\n        raise ValueError(\"val_losses must be non-empty\")\n    if patience < 1:\n        raise ValueError(\"patience must be >= 1\")\n\n    best_loss = float(losses[0].item())\n    best_epoch = 0\n    wait = 0\n\n    stop_epoch = losses.numel() - 1  # default to last epoch if no early stop\n    for i in range(1, losses.numel()):\n        current = float(losses[i].item())\n        # Improvement only if strictly more than min_delta\n        if (best_loss - current) > min_delta:\n            best_loss = current\n            best_epoch = i\n            wait = 0\n        else:\n            wait += 1\n            if wait >= patience:\n                stop_epoch = i\n                break\n\n    return int(stop_epoch), int(best_epoch)\n\n\ndef solution() -> Tuple[int, int]:\n    # Example usage mirroring the prompt\n    val_losses = [0.9, 0.8, 0.75, 0.77, 0.76, 0.77, 0.78]\n    patience = 2\n    min_delta = 0.01\n    result = early_stopping(val_losses, patience, min_delta)\n    # Expected: (4, 2)\n    print(result)\n    return result\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
