import { Problem } from '../../types';

export const DM_16_FEATURE_SCALING_IMPLEMENTATION: Problem = {
  "id": "dm_16_feature_scaling_implementation",
  "title": "Feature Scaling Implementation",
  "difficulty": "Easy",
  "tags": [
    "Linear Algebra",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Write a Python function that performs feature scaling on a dataset using both standardization and min-max normalization. The function should take a 2D NumPy array as input, where each row represents a data sample and each column represents a feature. It should return two 2D NumPy arrays: one scaled by standardization and one by min-max normalization. Make sure all results are rounded to the nearest 4th decimal.\n\nExample:\n\nInput:\n\ndata = np.array([[1, 2], [3, 4], [5, 6]])\n\nOutput:\n\n([[-1.2247, -1.2247], [0.0, 0.0], [1.2247, 1.2247]], [[0.0, 0.0], [0.5, 0.5], [1.0, 1.0]])\n\nReasoning:\n\nStandardization rescales each feature to have a mean of 0 and a standard deviation of 1. Min-max normalization rescales each feature to a range of [0, 1], where the minimum feature value maps to 0 and the maximum to 1.",
  "solutionExplanation": "We compute two types of feature scaling per feature (column). For standardization, we subtract the column-wise mean and divide by the column-wise standard deviation. This transforms each feature to have mean 0 and variance 1. Using PyTorch, we compute mean and standard deviation along dim=0 (features), and we use unbiased=False to match NumPy's default population standard deviation (ddof=0). For numerical stability, if a feature has zero standard deviation (constant column), we safely divide by 1, yielding zeros for that feature.\n\nFor min-max normalization, we compute the per-feature minimum and maximum and rescale values to [0, 1] using (x - min) / (max - min). If a feature has zero range (max equals min), we set the denominator to 1 so that all values map to 0, which is consistent with a constant feature. Finally, we round the results to 4 decimal places by multiplying by 1e4, rounding, and dividing back.\n\nAlthough the input and outputs are NumPy arrays per the problem, all computations are performed with PyTorch tensors for efficiency and to meet the requirement. We convert inputs to tensors and outputs back to NumPy.",
  "solutionCode": "import torch\nimport numpy as np\n\n\ndef feature_scaling(data: np.ndarray) -> (np.ndarray, np.ndarray):\n    \"\"\"\n    Perform per-feature standardization and min-max normalization using PyTorch.\n\n    Args:\n        data (np.ndarray): 2D array of shape (N, D), rows are samples and columns are features.\n\n    Returns:\n        standardized_data (np.ndarray): Standardized array (mean=0, std=1 per feature), rounded to 4 decimals.\n        normalized_data (np.ndarray): Min-max normalized array ([0, 1] per feature), rounded to 4 decimals.\n    \"\"\"\n    if data.ndim != 2:\n        raise ValueError(\"Input data must be a 2D NumPy array.\")\n\n    x = torch.as_tensor(data, dtype=torch.float32)\n\n    # Standardization: (x - mean) / std (population std to match NumPy's ddof=0)\n    mean = x.mean(dim=0)\n    std = x.std(dim=0, unbiased=False)\n    safe_std = torch.where(std > 0, std, torch.ones_like(std))\n    standardized = (x - mean) / safe_std\n\n    # Min-max normalization: (x - min) / (max - min)\n    min_vals = x.min(dim=0).values\n    max_vals = x.max(dim=0).values\n    range_vals = max_vals - min_vals\n    safe_range = torch.where(range_vals > 0, range_vals, torch.ones_like(range_vals))\n    normalized = (x - min_vals) / safe_range\n\n    # Round to 4 decimals\n    def round4(t: torch.Tensor) -> torch.Tensor:\n        return torch.round(t * 1e4) / 1e4\n\n    standardized = round4(standardized)\n    normalized = round4(normalized)\n\n    return standardized.cpu().numpy(), normalized.cpu().numpy()\n\n\ndef solution():\n    # Example usage\n    data = np.array([[1, 2], [3, 4], [5, 6]], dtype=np.float32)\n    standardized_data, normalized_data = feature_scaling(data)\n\n    # Print as lists for readability\n    print(\"Standardized:\", standardized_data.tolist())\n    print(\"Min-Max Normalized:\", normalized_data.tolist())\n\n    return standardized_data, normalized_data\n\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(N * D)",
  "spaceComplexity": "O(N * D)",
  "platform": "deepml"
};
