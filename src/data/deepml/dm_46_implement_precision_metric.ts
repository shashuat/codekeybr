import { Problem } from '../../types';

export const DM_46_IMPLEMENT_PRECISION_METRIC: Problem = {
  "id": "dm_46_implement_precision_metric",
  "title": "Implement Precision Metric",
  "difficulty": "Easy",
  "tags": [
    "Probability",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Write a Python function `precision` that calculates the precision metric given two arrays: `y_true` (true binary labels) and `y_pred` (predicted binary labels). Precision is defined as the ratio of true positives (TP) to the sum of true positives and false positives (TP + FP).\n\nPrecision = TP / (TP + FP)\n\nExample:\n\n```python\nimport numpy as np\n\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nresult = precision(y_true, y_pred)\nprint(result)  # Expected: 1.0\n```\n\nReasoning:\n- True Positives (TP) = 3\n- False Positives (FP) = 0\n- Precision = 3 / (3 + 0) = 1.0",
  "solutionExplanation": "Precision measures the fraction of predicted positives that are actually correct. Given binary labels, we can compute true positives by counting positions where both `y_true` and `y_pred` are 1, and false positives where `y_true` is 0 but `y_pred` is 1. The precision is then TP / (TP + FP).\n\nIn the PyTorch implementation, we convert inputs to tensors, flatten them, and construct boolean masks to identify TP and FP efficiently using elementwise logical operations and reductions. If there are no predicted positives (TP + FP == 0), we return 0.0 to avoid division by zero and to match common library behavior. The function also supports float predictions by optionally thresholding (default 0.5) to obtain binary predictions.",
  "solutionCode": "import torch\nimport torch.nn as nn\n\ndef precision(y_true, y_pred, threshold=None):\n    \"\"\"\n    Compute precision = TP / (TP + FP) for binary labels.\n\n    Args:\n        y_true: Array-like or torch.Tensor of shape (N,), true binary labels {0,1}.\n        y_pred: Array-like or torch.Tensor of shape (N,), predicted labels. If floating,\n                an optional threshold is applied to binarize.\n        threshold: Optional float threshold for binarizing float predictions (default 0.5 if needed).\n\n    Returns:\n        float: Precision score in [0, 1]. Returns 0.0 when there are no predicted positives.\n    \"\"\"\n    # Convert inputs to tensors\n    y_true_t = torch.as_tensor(y_true)\n    y_pred_t = torch.as_tensor(y_pred)\n\n    # Flatten to 1D\n    y_true_t = y_true_t.reshape(-1)\n    y_pred_t = y_pred_t.reshape(-1)\n\n    # Handle empty input\n    if y_true_t.numel() == 0:\n        return 0.0\n\n    # Binarize predictions if they are floating-point\n    if y_pred_t.dtype.is_floating_point:\n        thr = 0.5 if threshold is None else float(threshold)\n        y_pred_bin = (y_pred_t >= thr)\n    else:\n        # Convert integer {0,1} predictions to boolean\n        y_pred_bin = y_pred_t.to(torch.bool)\n\n    # Convert true labels to boolean\n    y_true_bin = y_true_t.to(torch.bool)\n\n    # Compute TP and FP using boolean masks\n    tp = torch.logical_and(y_true_bin, y_pred_bin).sum().item()\n    fp = torch.logical_and(~y_true_bin, y_pred_bin).sum().item()\n\n    denom = tp + fp\n    return float(tp / denom) if denom > 0 else 0.0\n\n\ndef solution():\n    # Example usage matching the problem statement\n    y_true = torch.tensor([1, 0, 1, 1, 0, 1])\n    y_pred = torch.tensor([1, 0, 1, 0, 0, 1])\n    result = precision(y_true, y_pred)\n    print(result)  # Expected: 1.0\n\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
