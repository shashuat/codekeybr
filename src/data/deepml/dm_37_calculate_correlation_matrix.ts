import { Problem } from '../../types';

export const DM_37_CALCULATE_CORRELATION_MATRIX: Problem = {
  "id": "dm_37_calculate_correlation_matrix",
  "title": "Calculate Correlation Matrix",
  "difficulty": "Medium",
  "tags": [
    "Linear Algebra",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Write a Python function to calculate the correlation matrix for a given dataset. The function should take in a 2D numpy array X and an optional 2D numpy array Y. If Y is not provided, the function should calculate the correlation matrix of X with itself. It should return the correlation matrix as a 2D numpy array.\n\nExample:\n- Input:\n  X = np.array([[1, 2],\n                [3, 4],\n                [5, 6]])\n  output = calculate_correlation_matrix(X)\n  print(output)\n- Output:\n  [[1. 1.]\n   [1. 1.]]\n\nReasoning: The function calculates the correlation matrix for the dataset X. In this example, the correlation between the two features is 1, indicating a perfect linear relationship.",
  "solutionExplanation": "The correlation matrix measures pairwise linear relationships between feature columns. For two matrices X \u2208 R^{n\u00d7d_x} and Y \u2208 R^{n\u00d7d_y}, the (i, j)-th entry is the Pearson correlation between column i of X and column j of Y. This is defined as cov(X_i, Y_j) / (std(X_i) \u00b7 std(Y_j)). If Y is omitted, we compute correlations among the columns of X, yielding a d\u00d7d matrix.\n\nA numerically stable and efficient approach is to standardize each column to zero mean and unit variance and then compute the matrix product of the transposed standardized X with standardized Y, divided by the number of samples n. Using PyTorch tensor operations, we can perform mean-centering and scaling along the column dimension and compute the correlation matrix with a single matrix multiplication. To avoid division by zero for constant columns, we clamp the standard deviation by a small epsilon.",
  "solutionCode": "import torch\nimport numpy as np\n\ndef calculate_correlation_matrix(X, Y=None):\n    \"\"\"\n    Calculate the correlation matrix between the columns of X and Y using PyTorch.\n\n    Args:\n        X (np.ndarray or torch.Tensor): Shape (n_samples, d_x)\n        Y (np.ndarray or torch.Tensor, optional): Shape (n_samples, d_y). If None, uses X.\n\n    Returns:\n        np.ndarray: Correlation matrix of shape (d_x, d_y) (or (d, d) if Y is None).\n    \"\"\"\n    # Convert inputs to double-precision PyTorch tensors\n    x = torch.as_tensor(X, dtype=torch.float64)\n    y = x if Y is None else torch.as_tensor(Y, dtype=torch.float64)\n\n    if x.dim() != 2 or y.dim() != 2:\n        raise ValueError(\"X and Y must be 2D arrays/tensors.\")\n    if x.shape[0] != y.shape[0]:\n        raise ValueError(\"X and Y must have the same number of rows (samples).\")\n\n    # Center columns (remove mean)\n    x = x - x.mean(dim=0, keepdim=True)\n    y = y - y.mean(dim=0, keepdim=True)\n\n    # Compute standard deviations per column; use unbiased=False -> denominator n\n    eps = 1e-12\n    x_std = x.std(dim=0, unbiased=False).clamp_min(eps)\n    y_std = y.std(dim=0, unbiased=False).clamp_min(eps)\n\n    # Standardize to unit variance\n    x = x / x_std\n    y = y / y_std\n\n    # Correlation matrix = (Zx^T Zy) / n\n    n = x.shape[0]\n    corr = (x.T @ y) / n\n\n    return corr.cpu().numpy()\n\n\ndef solution():\n    # Example usage\n    X = np.array([[1, 2],\n                  [3, 4],\n                  [5, 6]], dtype=float)\n    output = calculate_correlation_matrix(X)\n    print(output)\n\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(n * d_x * d_y)",
  "spaceComplexity": "O(n * (d_x + d_y) + d_x * d_y)",
  "platform": "deepml"
};
