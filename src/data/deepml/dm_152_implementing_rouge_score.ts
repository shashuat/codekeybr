import { Problem } from '../../types';

export const DM_152_IMPLEMENTING_ROUGE_SCORE: Problem = {
  "id": "dm_152_implementing_rouge_score",
  "title": "Implementing ROUGE Score",
  "difficulty": "Medium",
  "tags": [
    "Transformers",
    "Neural Networks"
  ],
  "descriptionMarkdown": "Implement the ROUGE-1 (Recall-Oriented Understudy for Gisting Evaluation) score to evaluate the quality of a generated summary by comparing it to a reference summary. ROUGE-1 focuses on unigram (single word) overlaps between the candidate and reference texts.\n\nYour task is to write a function that computes the ROUGE-1 recall, precision, and F1 score based on the number of overlapping unigrams.\n\nExample:\n\nInput:\n\nrouge_1_score('the cat sat on the mat', 'the cat is on the mat')\n\nOutput:\n\n{'precision': 0.8333333333333334, 'recall': 0.8333333333333334, 'f1': 0.8333333333333334}\n\nReasoning:\nThe reference text 'the cat sat on the mat' has 6 tokens, and the candidate text 'the cat is on the mat' has 6 tokens. The overlapping words are: 'the' (appears 2 times in reference, 2 times in candidate, so min(2,2)=2 overlap), 'cat' (1,1 \u2192 1 overlap), 'on' (1,1 \u2192 1 overlap), and 'mat' (1,1 \u2192 1 overlap). Total overlap = 2+1+1+1 = 5. Precision = 5/6 \u2248 0.833. Recall = 5/6 \u2248 0.833. F1 = 0.833 since precision equals recall.",
  "solutionExplanation": "ROUGE-1 measures the unigram overlap between a candidate summary and a reference summary. To compute it, we first tokenize both strings (typically lowercasing and splitting on whitespace). We then count the frequency of each token in both texts. The total overlap count is the sum of the element-wise minimum of these two frequency distributions across the union vocabulary of tokens.\n\nOnce we have the overlap, precision is defined as overlap divided by the total number of candidate tokens, recall is overlap divided by the total number of reference tokens, and the F1 score is the harmonic mean of precision and recall. Edge cases are handled safely: if the candidate or reference has zero tokens, the corresponding precision or recall becomes 0; if both precision and recall are zero, F1 is set to 0.\n\nThe implementation leverages PyTorch tensors to build unigram frequency vectors efficiently using torch.bincount and computes the overlap via element-wise minimum, ensuring a concise and performant solution.",
  "solutionCode": "import torch\nimport torch.nn as nn\nfrom typing import Dict\n\ndef rouge_1_score(reference: str, candidate: str) -> Dict[str, float]:\n    \"\"\"\n    Compute ROUGE-1 precision, recall, and F1 between reference and candidate texts.\n    - Tokenization: lowercase and split on whitespace.\n    - Overlap: sum of element-wise min of unigram frequency counts.\n\n    Args:\n        reference: The reference (gold) summary string.\n        candidate: The generated (candidate) summary string.\n\n    Returns:\n        A dict with keys 'precision', 'recall', and 'f1'.\n    \"\"\"\n    ref_tokens = reference.strip().lower().split() if reference is not None else []\n    cand_tokens = candidate.strip().lower().split() if candidate is not None else []\n\n    # Build vocabulary over union of tokens\n    vocab = {}\n    def add_tokens(tokens):\n        for w in tokens:\n            if w not in vocab:\n                vocab[w] = len(vocab)\n    add_tokens(ref_tokens)\n    add_tokens(cand_tokens)\n    vocab_size = len(vocab)\n\n    # Convert tokens to index tensors\n    ref_ids = torch.tensor([vocab[w] for w in ref_tokens], dtype=torch.long)\n    cand_ids = torch.tensor([vocab[w] for w in cand_tokens], dtype=torch.long)\n\n    # Frequency counts with torch (handles empty gracefully)\n    if vocab_size == 0:\n        ref_counts = torch.zeros(0, dtype=torch.long)\n        cand_counts = torch.zeros(0, dtype=torch.long)\n    else:\n        ref_counts = torch.bincount(ref_ids, minlength=vocab_size) if ref_ids.numel() > 0 else torch.zeros(vocab_size, dtype=torch.long)\n        cand_counts = torch.bincount(cand_ids, minlength=vocab_size) if cand_ids.numel() > 0 else torch.zeros(vocab_size, dtype=torch.long)\n\n    # Overlap is the sum of element-wise minimum counts\n    overlap = torch.minimum(ref_counts, cand_counts).sum().item()\n\n    total_ref = len(ref_tokens)\n    total_cand = len(cand_tokens)\n\n    precision = float(overlap) / total_cand if total_cand > 0 else 0.0\n    recall = float(overlap) / total_ref if total_ref > 0 else 0.0\n    f1 = 2.0 * precision * recall / (precision + recall) if (precision + recall) > 0.0 else 0.0\n\n    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}\n\n\ndef solution():\n    # Example usage\n    example_ref = 'the cat sat on the mat'\n    example_cand = 'the cat is on the mat'\n    scores = rouge_1_score(example_ref, example_cand)\n    print(scores)\n    return scores\n",
  "timeComplexity": "O(n + m)",
  "spaceComplexity": "O(V)",
  "platform": "deepml"
};
