import { Problem } from '../../types';

export const DM_154_EXPONENTIALLR_LEARNING_RATE_SCHEDULER: Problem = {
  "id": "dm_154_exponentiallr_learning_rate_scheduler",
  "title": "ExponentialLR Learning Rate Scheduler",
  "difficulty": "Easy",
  "tags": [
    "Optimization",
    "Gradient Descent"
  ],
  "descriptionMarkdown": "Write a Python class `ExponentialLRScheduler` to implement a learning rate scheduler based on the ExponentialLR strategy. The class should:\n\n- Initialize with `initial_lr` (float) and `gamma` (float).\n- Provide a method `get_lr(self, epoch)` that returns the current learning rate for a given epoch (int).\n- Decrease the learning rate by a factor of `gamma` every epoch, i.e., `lr(epoch) = initial_lr * gamma**epoch`.\n- Return the learning rate rounded to 4 decimal places.\n\nExample:\n\nInput:\n\n```\nscheduler = ExponentialLRScheduler(initial_lr=0.1, gamma=0.9)\nprint(f\"{scheduler.get_lr(epoch=0):.4f}\")\nprint(f\"{scheduler.get_lr(epoch=1):.4f}\")\nprint(f\"{scheduler.get_lr(epoch=2):.4f}\")\nprint(f\"{scheduler.get_lr(epoch=3):.4f}\")\n```\n\nOutput:\n\n```\n0.1000\n0.0900\n0.0810\n0.0729\n```",
  "solutionExplanation": "The ExponentialLR schedule decays the learning rate multiplicatively by a constant factor gamma at every epoch. Mathematically, the learning rate at epoch t is lr(t) = initial_lr * gamma^t. This strategy enables smooth, continuous decay that helps stabilize training by progressively taking smaller optimization steps as training proceeds.\n\nTo implement this, we store the initial learning rate and gamma in the scheduler and compute the learning rate for any epoch using the formula above. We use PyTorch tensor operations (torch.pow) for the exponentiation to comply with a PyTorch-based solution. The method returns the result rounded to four decimal places as required. We also include basic input validation to ensure robustness (non-negative epochs, positive initial_lr and gamma).",
  "solutionCode": "import torch\nimport torch.nn as nn\n\nclass ExponentialLRScheduler:\n    \"\"\"\n    Exponential learning rate scheduler: lr_t = initial_lr * gamma**epoch\n    Returns the learning rate rounded to 4 decimal places.\n    \"\"\"\n    def __init__(self, initial_lr: float, gamma: float) -> None:\n        # Basic type and value checks for robustness\n        if not isinstance(initial_lr, (int, float)):\n            raise TypeError(\"initial_lr must be a number (int or float)\")\n        if not isinstance(gamma, (int, float)):\n            raise TypeError(\"gamma must be a number (int or float)\")\n        if initial_lr <= 0:\n            raise ValueError(\"initial_lr must be > 0\")\n        if gamma <= 0:\n            raise ValueError(\"gamma must be > 0\")\n        self.initial_lr = float(initial_lr)\n        self.gamma = float(gamma)\n\n    def get_lr(self, epoch: int) -> float:\n        \"\"\"Compute the learning rate at the given epoch.\n        Args:\n            epoch (int): Non-negative epoch index.\n        Returns:\n            float: Learning rate rounded to 4 decimal places.\n        \"\"\"\n        if not isinstance(epoch, int):\n            raise TypeError(\"epoch must be an integer\")\n        if epoch < 0:\n            raise ValueError(\"epoch must be >= 0\")\n        # Use PyTorch tensor math for exponentiation\n        init = torch.tensor(self.initial_lr, dtype=torch.float64)\n        g = torch.tensor(self.gamma, dtype=torch.float64)\n        lr_t = init * torch.pow(g, epoch)\n        return round(float(lr_t.item()), 4)\n\n\ndef solution():\n    # Example usage demonstrating expected behavior\n    scheduler = ExponentialLRScheduler(initial_lr=0.1, gamma=0.9)\n    print(f\"{scheduler.get_lr(epoch=0):.4f}\")  # 0.1000\n    print(f\"{scheduler.get_lr(epoch=1):.4f}\")  # 0.0900\n    print(f\"{scheduler.get_lr(epoch=2):.4f}\")  # 0.0810\n    print(f\"{scheduler.get_lr(epoch=3):.4f}\")  # 0.0729\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(1)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
