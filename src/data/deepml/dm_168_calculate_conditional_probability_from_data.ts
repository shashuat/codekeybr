import { Problem } from '../../types';

export const DM_168_CALCULATE_CONDITIONAL_PROBABILITY_FROM_DATA: Problem = {
  "id": "dm_168_title_in_snake_case",
  "title": "Calculate Conditional Probability from Data",
  "difficulty": "Easy",
  "tags": [
    "Probability"
  ],
  "descriptionMarkdown": "Given a dataset of observations as a list of tuples, each tuple is of the form (X, Y), where X and Y are categorical variables (e.g., color, animal). Implement a function to compute the conditional probability P(Y = y | X = x), the probability that Y equals a specific value y, given that X equals a specific value x.\n\nYour task:\n- Write a function `conditional_probability(data, x, y)` that takes as input:\n  - `data`: List of (X, Y) tuples.\n  - `x`: Value for variable X to condition on.\n  - `y`: Value for variable Y whose probability you want given X = x.\n- The function should return the probability P(Y = y | X = x). Return 0.0 if there are no instances where X = x.\n\nExample:\n\ndata = [\n('red', 'cat'),\n('blue', 'dog'),\n('red', 'dog'),\n('red', 'cat'),\n('blue', 'cat'),\n('red', 'dog')\n]\nprint(conditional_probability(data, 'red', 'cat'))   # 0.5\nprint(conditional_probability(data, 'blue', 'cat'))  # 0.5\nprint(conditional_probability(data, 'green', 'cat')) # 0.0\n\nReasoning:\n- For X = 'red', there are 4 instances: 2 with Y = 'cat' and 2 with Y = 'dog'. So P(Y = cat | X = red) = 2/4 = 0.5.\n- For X = 'blue', there are 2 instances: 1 with Y = 'cat', 1 with Y = 'dog'. So P(Y = cat | X = blue) = 1/2 = 0.5.\n- For X = 'green', there are 0 instances, so output 0.0.",
  "solutionExplanation": "To compute P(Y = y | X = x), we count how many times X equals x (the denominator) and, among those, how many times Y equals y (the numerator). The conditional probability is then the ratio numerator/denominator. If there are no occurrences with X = x, the conditional probability is defined as 0.0.\n\nWe can implement this efficiently by converting the categorical variables to integer indices, forming PyTorch tensors, and using vectorized boolean masking to count matches. This avoids explicit Python loops over the dataset and provides a clean, efficient approach. We also handle edge cases: when x does not appear in the data, we immediately return 0.0; when y does not appear, the numerator is zero, resulting in probability 0.0.",
  "solutionCode": "import torch\nimport torch.nn as nn\nfrom typing import List, Tuple, Any\n\ndef conditional_probability(data: List[Tuple[Any, Any]], x: Any, y: Any) -> float:\n    \"\"\"\n    Compute P(Y = y | X = x) from a list of (X, Y) categorical pairs using PyTorch operations.\n\n    Args:\n        data: List of (X, Y) tuples.\n        x: Value for variable X to condition on.\n        y: Value for variable Y whose probability is computed given X = x.\n\n    Returns:\n        float: Conditional probability rounded to 4 decimal places.\n               Returns 0.0 if there are no instances where X = x.\n    \"\"\"\n    # Handle empty data quickly\n    if not data:\n        return 0.0\n\n    # Separate X and Y columns\n    x_vals = [pair[0] for pair in data]\n    y_vals = [pair[1] for pair in data]\n\n    # Build categorical mappings for X and Y\n    x_to_id = {}\n    for v in x_vals:\n        if v not in x_to_id:\n            x_to_id[v] = len(x_to_id)\n\n    y_to_id = {}\n    for v in y_vals:\n        if v not in y_to_id:\n            y_to_id[v] = len(y_to_id)\n\n    # If x never occurs, the conditional probability is 0.0 by definition\n    if x not in x_to_id:\n        return 0.0\n\n    # Convert data to PyTorch tensors of indices\n    x_ids = torch.tensor([x_to_id[v] for v in x_vals], dtype=torch.long)\n    y_ids = torch.tensor([y_to_id[v] for v in y_vals], dtype=torch.long)\n\n    x_id = torch.tensor(x_to_id[x], dtype=torch.long)\n\n    # Mask where X == x\n    mask_x = (x_ids == x_id)\n    denom = int(mask_x.sum().item())\n\n    if denom == 0:\n        return 0.0\n\n    # If y never occurs, numerator is zero -> probability is 0.0\n    if y not in y_to_id:\n        return 0.0\n\n    y_id = torch.tensor(y_to_id[y], dtype=torch.long)\n\n    # Mask where Y == y and combine with X == x\n    mask_y = (y_ids == y_id)\n    numerator = int(torch.logical_and(mask_x, mask_y).sum().item())\n\n    prob = numerator / denom\n    return round(float(prob), 4)\n\n\ndef solution():\n    # Example usage\n    data = [\n        ('red', 'cat'),\n        ('blue', 'dog'),\n        ('red', 'dog'),\n        ('red', 'cat'),\n        ('blue', 'cat'),\n        ('red', 'dog')\n    ]\n    print(conditional_probability(data, 'red', 'cat'))   # Expected: 0.5\n    print(conditional_probability(data, 'blue', 'cat'))  # Expected: 0.5\n    print(conditional_probability(data, 'green', 'cat')) # Expected: 0.0\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(N)",
  "platform": "deepml"
};
