import { Problem } from '../../types';

export const DM_61_IMPLEMENT_F_SCORE_CALCULATION_FOR_BINARY_CLASSIFICATION: Problem = {
  "id": "dm_61_implement_f_score_calculation_for_binary_classification",
  "title": "Implement F-Score Calculation for Binary Classification",
  "difficulty": "Easy",
  "tags": [
    "Probability",
    "Loss Functions",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Task: Implement F-Score Calculation for Binary Classification\n\nImplement a function `f_score(y_true, y_pred, beta)` that computes the F-Score (F-beta score) for a binary classification task. The F-Score combines Precision and Recall into a single metric and is defined as:\n\nF_beta = (1 + beta^2) * (Precision * Recall) / (beta^2 * Precision + Recall)\n\n- `y_true`: Numpy array of true labels (binary)\n- `y_pred`: Numpy array of predicted labels (binary)\n- `beta`: Float that weights the importance of Recall relative to Precision. When `beta = 1`, it yields the F1-Score.\n\nReturn the F-Score rounded to three decimal places.\n\nExample:\n\nInput:\n- `y_true = np.array([1, 0, 1, 1, 0, 1])`\n- `y_pred = np.array([1, 0, 1, 0, 0, 1])`\n- `beta = 1`\n\nOutput:\n- `0.857`",
  "solutionExplanation": "The F-beta score balances precision and recall according to a weighting parameter beta. Precision measures the fraction of predicted positives that are true positives (TP/(TP+FP)), while recall measures the fraction of actual positives correctly identified (TP/(TP+FN)). The F-beta score is the weighted harmonic mean of precision and recall:\n\nF_beta = (1 + beta^2) * (Precision * Recall) / (beta^2 * Precision + Recall)\n\nTo compute this efficiently, we first binarize the inputs (non-zero as positive), then compute TP, FP, and FN using vectorized tensor operations. We handle edge cases where denominators become zero by defining precision or recall as zero, and similarly setting the F-beta score to zero when its denominator is zero. Finally, we round the result to three decimals, as required.",
  "solutionCode": "import torch\nimport torch.nn as nn\n\ndef f_score(y_true, y_pred, beta: float) -> float:\n    \"\"\"\n    Calculate the F-beta score for a binary classification task using PyTorch ops.\n\n    Args:\n        y_true: Array-like of true binary labels (numpy array, list, or torch tensor).\n        y_pred: Array-like of predicted binary labels (numpy array, list, or torch tensor).\n        beta: Non-negative float weighting recall relative to precision (beta=1 -> F1).\n\n    Returns:\n        float: F-beta score rounded to three decimal places.\n    \"\"\"\n    if beta < 0:\n        raise ValueError(\"beta must be non-negative\")\n\n    # Convert inputs to torch tensors and flatten\n    y_true_t = torch.as_tensor(y_true).view(-1)\n    y_pred_t = torch.as_tensor(y_pred).view(-1)\n\n    # Binarize: any non-zero value is treated as positive\n    y_true_b = y_true_t != 0\n    y_pred_b = y_pred_t != 0\n\n    # Compute confusion matrix components using boolean tensor ops\n    tp = torch.count_nonzero(y_true_b & y_pred_b).to(torch.float64)\n    fp = torch.count_nonzero(~y_true_b & y_pred_b).to(torch.float64)\n    fn = torch.count_nonzero(y_true_b & ~y_pred_b).to(torch.float64)\n\n    # Precision and recall with zero-division handling\n    precision_den = tp + fp\n    recall_den = tp + fn\n\n    precision = torch.where(precision_den > 0, tp / precision_den, torch.tensor(0.0, dtype=torch.float64))\n    recall = torch.where(recall_den > 0, tp / recall_den, torch.tensor(0.0, dtype=torch.float64))\n\n    beta2 = float(beta) * float(beta)\n    beta2_t = torch.tensor(beta2, dtype=torch.float64)\n\n    denom = beta2_t * precision + recall\n    f_beta = torch.where(denom > 0, (1.0 + beta2_t) * precision * recall / denom, torch.tensor(0.0, dtype=torch.float64))\n\n    return round(float(f_beta.item()), 3)\n\n\ndef solution():\n    # Example usage\n    import numpy as np\n    y_true = np.array([1, 0, 1, 1, 0, 1])\n    y_pred = np.array([1, 0, 1, 0, 0, 1])\n    beta = 1\n    result = f_score(y_true, y_pred, beta)\n    print(result)  # Expected: 0.857\n    return result\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
