import { Problem } from '../../types';

export const DM_48_IMPLEMENT_REDUCED_ROW_ECHELON_FORM__RREF__FUNCTION: Problem = {
  "id": "dm_48_implement_reduced_row_echelon_form_rref_function",
  "title": "Implement Reduced Row Echelon Form (RREF) Function",
  "difficulty": "Medium",
  "tags": [
    "Linear Algebra",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Implement a function that converts a given matrix into its Reduced Row Echelon Form (RREF). In RREF, each pivot (leading nonzero entry of a row) is 1, and all other entries in the pivot's column are 0.\n\nDetails to handle:\n- Diagonal entries can be 0 if the matrix is reducible (e.g., the corresponding row can be eliminated entirely).\n- Some rows may be entirely zeros.\n- If a column contains a pivot (leading 1), all other entries in that column should be zero.\n\nExample:\n\nInput matrix:\n\n[ [  1,  2, -1,  -4],\n  [  2,  3, -1, -11],\n  [ -2,  0, -3,  22] ]\n\nExpected RREF:\n\n[ [1, 0, 0, -8],\n  [0, 1, 0,  1],\n  [0, 0, 1, -2] ]\n\nYour task: Implement the RREF algorithm that robustly handles these cases.",
  "solutionExplanation": "The Reduced Row Echelon Form can be obtained using Gauss-Jordan elimination. We iterate over columns, and for each column we try to find a pivot row starting from the current working row. To improve numerical stability and avoid dividing by very small numbers, we perform partial pivoting by choosing the row with the largest absolute value in the current column as the pivot. If the best pivot is effectively zero, we skip that column.\n\nOnce a pivot is found, we swap it into the working row (if necessary), normalize the pivot row so that the pivot element becomes 1, and then eliminate all other entries in the same column (both above and below) by subtracting appropriate multiples of the pivot row from every other row. Advancing the working row as we move through columns yields an upper echelon structure which, due to the full elimination step for all rows, is in reduced row echelon form at the end. Finally, we zero-out tiny numerical artifacts under a tolerance to produce a clean RREF.",
  "solutionCode": "import torch\n\n\ndef rref(matrix: torch.Tensor, tol: float = 1e-12) -> torch.Tensor:\n    \"\"\"\n    Compute the Reduced Row Echelon Form (RREF) of a matrix using Gauss-Jordan elimination.\n\n    Args:\n        matrix: A 2D torch.Tensor of shape (m, n).\n        tol: Tolerance used to treat small values as zero for numerical stability.\n\n    Returns:\n        A new tensor containing the RREF of the input matrix.\n    \"\"\"\n    if matrix.dim() != 2:\n        raise ValueError('Input must be a 2D tensor (matrix).')\n\n    # Work in float64 for stability; operate on a copy to avoid in-place modification of the input\n    A = matrix.clone().detach().to(dtype=torch.float64)\n    m, n = A.shape\n\n    row = 0  # Current pivot row\n    for col in range(n):\n        if row >= m:\n            break\n\n        # Partial pivoting: find the row with the largest absolute value in this column from 'row' downward\n        pivot_rel = torch.argmax(torch.abs(A[row:, col])).item()\n        pivot_row = row + pivot_rel\n        pivot_val = A[pivot_row, col]\n\n        # If pivot is effectively zero, skip this column\n        if torch.abs(pivot_val) <= tol:\n            continue\n\n        # Swap current row with pivot_row if needed\n        if pivot_row != row:\n            tmp = A[row].clone()\n            A[row] = A[pivot_row]\n            A[pivot_row] = tmp\n\n        # Normalize pivot row so that pivot becomes 1\n        A[row] = A[row] / A[row, col]\n\n        # Eliminate all other entries in this column\n        for r in range(m):\n            if r == row:\n                continue\n            factor = A[r, col]\n            if torch.abs(factor) > tol:\n                A[r] = A[r] - factor * A[row]\n\n        row += 1\n\n    # Clean up tiny numerical noise\n    A[torch.abs(A) < tol] = 0.0\n    return A\n\n\ndef solution():\n    # Example usage\n    matrix = torch.tensor([\n        [1.0, 2.0, -1.0, -4.0],\n        [2.0, 3.0, -1.0, -11.0],\n        [-2.0, 0.0, -3.0, 22.0]\n    ], dtype=torch.float64)\n\n    rref_matrix = rref(matrix)\n    print(rref_matrix)\n\n\nif __name__ == '__main__':\n    solution()\n",
  "timeComplexity": "O(m n min(m, n)) \u2248 O(m n^2) for m \u2265 n",
  "spaceComplexity": "O(m n) to store the matrix; O(1) auxiliary space beyond the output copy",
  "platform": "deepml"
};
