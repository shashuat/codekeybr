import { Problem } from '../../types';

export const DM_50_IMPLEMENT_LASSO_REGRESSION_USING_GRADIENT_DESCENT: Problem = {
  "id": "dm_50_implement_lasso_regression_using_gradient_descent",
  "title": "Implement Lasso Regression using Gradient Descent",
  "difficulty": "Medium",
  "tags": [
    "Optimization",
    "Regularization",
    "Gradient Descent",
    "Loss Functions",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Implement Lasso Regression (Least Absolute Shrinkage and Selection Operator) using Gradient Descent. Lasso uses L1 regularization, adding a penalty equal to the sum of absolute values of the weights to encourage sparsity (feature selection by driving some coefficients to zero).\n\nObjective function:\n\nJ(w, b) = MSE(y, Xw + b) + alpha * ||w||_1\n\n- MSE(y, Xw + b) = (1/n) * sum_i (y_i - (w^T x_i + b))^2\n- ||w||_1 = sum_j |w_j|\n- b (bias) is not regularized\n\nTask: Implement gradient descent to minimize J(w, b) and return the optimized weights and bias.\n\nExample:\n- X = [[0, 0], [1, 1], [2, 2]]\n- y = [0, 1, 2]\n- alpha = 0.1\n- After optimization (lr=0.01, max_iter=1000), a valid solution is approximately:\n  - w \u2248 [0.4237, 0.4237]\n  - b \u2248 0.1539",
  "solutionExplanation": "Lasso regression augments the mean squared error with an L1 penalty on the weights. The L1 penalty encourages sparsity by shrinking some coefficients exactly to zero, effectively performing feature selection. The bias term is not penalized. The objective we minimize is J(w, b) = (1/n) sum (y_i - (w^T x_i + b))^2 + alpha * ||w||_1.\n\nTo optimize via gradient descent, we use the standard gradients for the MSE part and a subgradient for the L1 term. Let r = Xw + b - y be the residual vector. Using the averaged MSE, the gradients are: \u2202J/\u2202w = (2/n) X^T r + alpha * sign(w) and \u2202J/\u2202b = (2/n) sum(r). The L1 term is not differentiable at zero; we use a valid subgradient with sign(0) = 0. We iteratively update w and b with a chosen learning rate until convergence or a maximum number of iterations is reached.\n\nWith identical feature columns, the L1 penalty distributes weight symmetrically across them, producing equal coefficients. Regularization strength alpha controls the amount of shrinkage; larger alpha yields sparser solutions. We stop early if the objective improvement falls below a tolerance.",
  "solutionCode": "import torch\n\ndef l1_regularization_gradient_descent(X, y, alpha=0.1, learning_rate=0.01, max_iter=1000, tol=1e-6, verbose=False):\n    \"\"\"\n    Lasso regression via gradient descent with L1 subgradient (manual updates).\n\n    Args:\n        X (np.ndarray or torch.Tensor): Feature matrix of shape (n_samples, n_features)\n        y (np.ndarray or torch.Tensor): Target vector of shape (n_samples,)\n        alpha (float): L1 regularization strength\n        learning_rate (float): Gradient descent step size\n        max_iter (int): Maximum number of iterations\n        tol (float): Convergence tolerance on objective improvement\n        verbose (bool): If True, logs progress every 100 iterations\n\n    Returns:\n        (torch.Tensor, torch.Tensor): (weights, bias) where weights has shape (n_features,) and bias is a scalar tensor\n    \"\"\"\n    # Convert inputs to double tensors for stable optimization\n    if not isinstance(X, torch.Tensor):\n        X_t = torch.tensor(X, dtype=torch.float64)\n    else:\n        X_t = X.detach().clone().to(dtype=torch.float64)\n\n    if not isinstance(y, torch.Tensor):\n        y_t = torch.tensor(y, dtype=torch.float64).view(-1)\n    else:\n        y_t = y.detach().clone().to(dtype=torch.float64).view(-1)\n\n    n, p = X_t.shape\n\n    # Initialize parameters\n    w = torch.zeros(p, dtype=torch.float64)\n    b = torch.tensor(0.0, dtype=torch.float64)\n\n    prev_obj = float('inf')\n\n    for it in range(max_iter):\n        # Forward pass\n        pred = X_t.mv(w) + b  # shape: (n,)\n        residual = pred - y_t\n\n        # Objective components\n        mse = residual.pow(2).mean()  # (1/n) * sum (residual^2)\n        l1_penalty = alpha * torch.sum(torch.abs(w))\n        obj = mse + l1_penalty\n\n        # Subgradients\n        grad_w = (2.0 / n) * X_t.t().mv(residual) + alpha * torch.sign(w)\n        grad_b = (2.0 / n) * torch.sum(residual)\n\n        # Parameter updates\n        w = w - learning_rate * grad_w\n        b = b - learning_rate * grad_b\n\n        # Convergence check\n        if torch.abs(obj - prev_obj) < tol:\n            if verbose:\n                print(f\"Converged at iter {it} with objective {obj.item():.6f}\")\n            break\n        prev_obj = obj\n\n        if verbose and (it % 100 == 0 or it == max_iter - 1):\n            print(f\"iter {it:4d} | obj={obj.item():.6f} | mse={mse.item():.6f} | l1={l1_penalty.item():.6f}\")\n\n    return w, b\n\n\ndef solution():\n    # Example usage matching the prompt\n    X = torch.tensor([[0.0, 0.0], [1.0, 1.0], [2.0, 2.0]], dtype=torch.float64)\n    y = torch.tensor([0.0, 1.0, 2.0], dtype=torch.float64)\n    alpha = 0.1\n\n    w, b = l1_regularization_gradient_descent(\n        X, y, alpha=alpha, learning_rate=0.01, max_iter=1000, tol=1e-8\n    )\n\n    # Print results for inspection; return as a tuple for programmatic use\n    print(\"Weights:\", w.detach().numpy())\n    print(\"Bias:\", float(b.item()))\n    return w, b\n",
  "timeComplexity": "O(n * p * T) where n is samples, p is features, T is iterations",
  "spaceComplexity": "O(n * p) to store X plus O(p) for parameters",
  "platform": "deepml"
};
