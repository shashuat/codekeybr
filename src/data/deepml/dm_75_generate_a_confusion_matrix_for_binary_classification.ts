import { Problem } from '../../types';

export const DM_75_GENERATE_A_CONFUSION_MATRIX_FOR_BINARY_CLASSIFICATION: Problem = {
  "id": "dm_75_generate_a_confusion_matrix_for_binary_classification",
  "title": "Generate a Confusion Matrix for Binary Classification",
  "difficulty": "Easy",
  "tags": [
    "Probability",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Task: Generate a Confusion Matrix\n\nImplement the function `confusion_matrix(data)` that returns the 2\u00d72 confusion matrix for a binary classification problem. Each element in `data` is a pair `[y_true, y_pred]`, where `y_true` is the ground-truth label and `y_pred` is the predicted label.\n\nInput:\n- A list of lists, where each inner list is `[y_true, y_pred]` for one observation.\n\nOutput:\n- A 2\u00d72 confusion matrix represented as a list of lists in the format `[[TP, FN], [FP, TN]]`.\n\nExample:\n- Input: `data = [[1, 1], [1, 0], [0, 1], [0, 0], [0, 1]]`\n- Output: `[[1, 1], [2, 1]]`\n\nReasoning: The confusion matrix shows the counts of true positives (TP), false negatives (FN), false positives (FP), and true negatives (TN). In the example, TP=1, FN=1, FP=2, TN=1.",
  "solutionExplanation": "To build the confusion matrix for binary classification, we need to count how many predictions fall into the four categories: true positives (y_true=1 and y_pred=1), false negatives (y_true=1 and y_pred=0), false positives (y_true=0 and y_pred=1), and true negatives (y_true=0 and y_pred=0). These counts map directly to the 2\u00d72 matrix [[TP, FN], [FP, TN]].\n\nWe implement this efficiently using PyTorch tensors and vectorized logical operations. After converting the input list to a tensor, we binarize labels by treating any non-zero value as positive, then compute logical masks for each case and sum them to get the counts. This approach avoids Python loops and is both concise and efficient.\n\nThe function returns the resulting confusion matrix as a list of lists, preserving the requested output format. It also handles edge cases like empty input gracefully by returning a zero matrix.",
  "solutionCode": "import torch\n\n\ndef confusion_matrix(data):\n    \"\"\"\n    Generate a 2x2 confusion matrix for binary classification.\n\n    Args:\n        data (List[List[int]]): Each inner list is [y_true, y_pred].\n                                 Non-zero values are treated as positive (1), zero as negative (0).\n\n    Returns:\n        List[List[int]]: Confusion matrix in the form [[TP, FN], [FP, TN]].\n    \"\"\"\n    # Convert input to a torch tensor\n    t = torch.as_tensor(data)\n\n    # Handle empty input\n    if t.numel() == 0:\n        return [[0, 0], [0, 0]]\n\n    if t.ndim != 2 or t.size(1) != 2:\n        raise ValueError(\"Input must be a 2D array-like with shape (N, 2): [y_true, y_pred].\")\n\n    y_true = t[:, 0]\n    y_pred = t[:, 1]\n\n    # Binarize: treat any non-zero as positive\n    y_true = (y_true != 0)\n    y_pred = (y_pred != 0)\n\n    # Compute confusion matrix components using vectorized logical operations\n    tp = torch.logical_and(y_true, y_pred).sum().item()\n    fn = torch.logical_and(y_true, torch.logical_not(y_pred)).sum().item()\n    fp = torch.logical_and(torch.logical_not(y_true), y_pred).sum().item()\n    tn = torch.logical_and(torch.logical_not(y_true), torch.logical_not(y_pred)).sum().item()\n\n    return [[int(tp), int(fn)], [int(fp), int(tn)]]\n\n\n# Example usage\nif __name__ == \"__main__\":\n    data = [[1, 1], [1, 0], [0, 1], [0, 0], [0, 1]]\n    print(confusion_matrix(data))  # Expected: [[1, 1], [2, 1]]\n",
  "timeComplexity": "O(N)",
  "spaceComplexity": "O(1)",
  "platform": "deepml"
};
