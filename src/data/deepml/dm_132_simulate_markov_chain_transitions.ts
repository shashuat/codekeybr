import { Problem } from '../../types';

export const DM_132_SIMULATE_MARKOV_CHAIN_TRANSITIONS: Problem = {
  "id": "dm_132_simulate_markov_chain_transitions",
  "title": "Simulate Markov Chain Transitions",
  "difficulty": "Medium",
  "tags": [
    "Probability"
  ],
  "descriptionMarkdown": "Implement a function to simulate a Markov Chain. The function should take:\n- a 2D array representing the transition matrix (each row sums to 1),\n- an integer for the initial state index,\n- and an integer for the number of steps to simulate.\n\nIt should return an array containing the sequence of state indices over time, including the initial state. The next state at each step is sampled according to the transition probabilities of the current state's row.\n\nExample:\n\nInput:\n\ntransition_matrix = np.array([[0.8, 0.2], [0.3, 0.7]])\nsimulate_markov_chain(transition_matrix, 0, 3)\n\nPossible Output:\n[0 0 1 1]\n\nReasoning:\nStarting from state 0, each subsequent state is drawn from the row-wise categorical distribution of the transition matrix. For the given input, one valid simulated trajectory over three steps is [0, 0, 1, 1].",
  "solutionExplanation": "A Markov chain is defined by a transition matrix where each row gives the categorical probabilities of moving from a current state to the next state. To simulate the chain for a specified number of steps, we start at the given initial state and iteratively sample the next state from the distribution in the corresponding row of the transition matrix.\n\nIn PyTorch, we can use torch.multinomial to perform categorical sampling from a probability vector. Before sampling, we ensure the transition matrix is valid by clamping any negative values to zero and normalizing rows to sum to one (this adds robustness to minor numerical issues). We then record the initial state and sample the next state step-by-step, building a sequence of length num_steps + 1. The overall complexity scales linearly in the number of steps and the number of states per sampling.",
  "solutionCode": "import torch\nfrom typing import Union\n\n\ndef simulate_markov_chain(transition_matrix: Union[torch.Tensor, 'np.ndarray', list],\n                          initial_state: int,\n                          num_steps: int):\n    \"\"\"\n    Simulate a Markov chain given a transition matrix.\n\n    Args:\n        transition_matrix: Square matrix-like (torch.Tensor, numpy.ndarray, or list of lists)\n            where each row contains transition probabilities from a state and sums to 1.\n        initial_state: Integer index of the starting state (0-based).\n        num_steps: Number of transitions to simulate.\n\n    Returns:\n        numpy.ndarray of shape (num_steps + 1,) containing the sequence of visited state indices,\n        including the initial state at index 0.\n    \"\"\"\n    # Convert to a torch tensor (float64 for numerical stability)\n    tm = torch.as_tensor(transition_matrix, dtype=torch.float64)\n\n    # Basic validation\n    if tm.dim() != 2 or tm.size(0) != tm.size(1):\n        raise ValueError(\"transition_matrix must be a square 2D matrix.\")\n\n    n_states = tm.size(0)\n    if not (0 <= int(initial_state) < n_states):\n        raise ValueError(\"initial_state must be within [0, n_states-1].\")\n\n    if num_steps < 0:\n        raise ValueError(\"num_steps must be non-negative.\")\n\n    # Ensure non-negative and normalize rows to sum to 1 (robustness to minor deviations)\n    tm = torch.clamp(tm, min=0.0)\n    row_sums = tm.sum(dim=1, keepdim=True)\n\n    # Handle any zero rows (fallback to uniform distribution for that row)\n    zero_rows = (row_sums.squeeze(1) == 0)\n    if zero_rows.any():\n        tm[zero_rows] = 1.0\n        row_sums = tm.sum(dim=1, keepdim=True)\n\n    tm = tm / row_sums\n\n    # Prepare output sequence (torch tensor, will convert to numpy at the end)\n    seq = torch.empty(num_steps + 1, dtype=torch.long)\n    current = int(initial_state)\n    seq[0] = current\n\n    # Iteratively sample next state using categorical sampling per row\n    for t in range(1, num_steps + 1):\n        probs = tm[current]  # shape: (n_states,)\n        next_state = torch.multinomial(probs, num_samples=1, replacement=True).item()\n        seq[t] = next_state\n        current = next_state\n\n    # Return numpy array for compatibility with the original problem statement\n    return seq.numpy()\n\n\nif __name__ == \"__main__\":\n    # Example usage\n    import numpy as np\n\n    torch.manual_seed(0)  # for reproducibility of the example\n    transition_matrix = np.array([[0.8, 0.2],\n                                  [0.3, 0.7]], dtype=float)\n    result = simulate_markov_chain(transition_matrix, initial_state=0, num_steps=3)\n    print(result)\n",
  "timeComplexity": "O(steps * num_states)",
  "spaceComplexity": "O(steps)",
  "platform": "deepml"
};
