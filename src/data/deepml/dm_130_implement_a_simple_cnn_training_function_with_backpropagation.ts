import { Problem } from '../../types';

export const DM_130_IMPLEMENT_A_SIMPLE_CNN_TRAINING_FUNCTION_WITH_BACKPROPAGATION: Problem = {
  "id": "dm_130_implement_a_simple_cnn_training_function_with_backpropagation",
  "title": "Implement a Simple CNN Training Function with Backpropagation",
  "difficulty": "Hard",
  "tags": [
    "Neural Networks",
    "CNNs",
    "Backpropagation",
    "Gradient Descent",
    "Activation Functions",
    "Loss Functions",
    "Optimization"
  ],
  "descriptionMarkdown": "Create a function that trains a basic Convolutional Neural Network (CNN) using backpropagation. The network should include one convolutional layer with ReLU activation, followed by flattening and a dense layer with softmax output, and a cross-entropy loss. You need to handle the forward pass, compute the loss gradients, and update the weights and biases using stochastic gradient descent (SGD). Ensure the function processes input data as grayscale images and one-hot encoded labels, and returns the trained weights and biases for the convolutional and dense layers.\n\nRequirements:\n- Input X has shape (n_samples, height, width) for grayscale images.\n- Labels y are one-hot encoded with shape (n_samples, num_classes).\n- Network: Conv2D (valid padding) -> ReLU -> Flatten -> Dense -> Softmax output.\n- Loss: cross-entropy.\n- Optimizer: SGD with manual parameter updates.\n- Return: trained weights and biases for the convolutional and dense layers.\n\nExample:\n```\nimport numpy as np; np.random.seed(42)\nX = np.array([[[1, 2, 3],\n               [4, 5, 6],\n               [7, 8, 9]]])\ny = np.array([[1, 0]])\nprint(train_simple_cnn_with_backprop(X, y, 1, 0.01, 3, 1))\n```\n",
  "solutionExplanation": "We build a minimal CNN with a single convolutional layer followed by a ReLU nonlinearity, a flatten operation, and a final fully connected (dense) layer that outputs class logits. The model processes single-channel (grayscale) inputs of shape (H, W). With valid convolution (no padding, stride 1), the convolutional output has spatial size H_out = H - K + 1 and W_out = W - K + 1 for a kernel size K. Flattening yields a feature vector of length F * H_out * W_out, where F is the number of filters. The dense layer maps this vector to the number of classes C. We compute the loss as cross-entropy between the predicted logits and the one-hot encoded labels using log-softmax for numerical stability.\n\nFor training, we perform stochastic gradient descent by iterating sample-by-sample. For each sample, we run a forward pass, compute the loss, backpropagate gradients using PyTorch autograd (loss.backward), and update parameters with manual SGD steps inside a no_grad context. We explicitly zero gradients after each update. This approach respects the requirement to implement the forward pass, compute gradients with backpropagation, and update weights via SGD, while leveraging PyTorch's efficient tensor operations and automatic differentiation.\n\nFinally, we return the learned weights and biases for both layers. For clarity, we return the convolution weights permuted to (kernel_size, kernel_size, num_filters) from PyTorch's internal (num_filters, in_channels, kernel_size, kernel_size) layout, along with the convolution bias, and the dense layer's weight of shape (flat_dim, num_classes) and bias of shape (num_classes,).",
  "solutionCode": "import numpy as np\nimport torch\nimport torch.nn.functional as F\n\n\ndef train_simple_cnn_with_backprop(X, y, epochs, learning_rate, kernel_size=3, num_filters=1):\n    \"\"\"\n    Train a simple CNN (Conv2D -> ReLU -> Flatten -> Dense -> Softmax) using SGD and backpropagation.\n\n    Parameters:\n        X (np.ndarray): Input data of shape (n_samples, height, width), grayscale images.\n        y (np.ndarray): One-hot labels of shape (n_samples, num_classes).\n        epochs (int): Number of epochs.\n        learning_rate (float): SGD learning rate.\n        kernel_size (int): Convolution kernel size (square kernel).\n        num_filters (int): Number of convolutional filters.\n\n    Returns:\n        tuple: (conv_weights, conv_bias, dense_weights, dense_bias)\n            - conv_weights: np.ndarray of shape (kernel_size, kernel_size, num_filters)\n            - conv_bias: np.ndarray of shape (num_filters,)\n            - dense_weights: np.ndarray of shape (flat_dim, num_classes)\n            - dense_bias: np.ndarray of shape (num_classes,)\n    \"\"\"\n    # Convert inputs to torch tensors\n    X_t = torch.tensor(X, dtype=torch.float32)\n    y_t = torch.tensor(y, dtype=torch.float32)\n\n    n_samples, H, W = X_t.shape\n    num_classes = y_t.shape[1]\n\n    # Validate kernel size\n    if kernel_size > H or kernel_size > W:\n        raise ValueError(\"kernel_size must be <= min(height, width)\")\n\n    # Output spatial dimensions after valid convolution\n    H_out = H - kernel_size + 1\n    W_out = W - kernel_size + 1\n\n    flat_dim = num_filters * H_out * W_out\n\n    # Initialize parameters (small random init for weights, zeros for biases)\n    # Use a fixed seed for reproducibility if desired; comment/uncomment as needed\n    # torch.manual_seed(42)\n    conv_w = torch.randn(num_filters, 1, kernel_size, kernel_size, dtype=torch.float32) * 0.01\n    conv_b = torch.zeros(num_filters, dtype=torch.float32)\n\n    dense_w = torch.randn(flat_dim, num_classes, dtype=torch.float32) * 0.01\n    dense_b = torch.zeros(num_classes, dtype=torch.float32)\n\n    # Enable gradient tracking\n    conv_w.requires_grad_(True)\n    conv_b.requires_grad_(True)\n    dense_w.requires_grad_(True)\n    dense_b.requires_grad_(True)\n\n    for _ in range(epochs):\n        # Stochastic Gradient Descent: update per sample\n        for i in range(n_samples):\n            # Prepare sample and label\n            x_i = X_t[i].unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)\n            y_i = y_t[i].unsqueeze(0)               # (1, C)\n\n            # Zero grads from previous step\n            if conv_w.grad is not None:\n                conv_w.grad.zero_()\n            if conv_b.grad is not None:\n                conv_b.grad.zero_()\n            if dense_w.grad is not None:\n                dense_w.grad.zero_()\n            if dense_b.grad is not None:\n                dense_b.grad.zero_()\n\n            # Forward pass: Conv -> ReLU -> Flatten -> Dense (logits)\n            conv_out = F.conv2d(x_i, conv_w, bias=conv_b, stride=1, padding=0)  # (1, F, H_out, W_out)\n            act = F.relu(conv_out)\n            flat = act.view(1, -1)                                              # (1, flat_dim)\n            logits = flat @ dense_w + dense_b                                    # (1, C)\n\n            # Cross-entropy with one-hot labels using log_softmax for stability\n            log_probs = F.log_softmax(logits, dim=1)                             # (1, C)\n            loss = -(y_i * log_probs).sum()                                      # scalar (per-sample loss)\n\n            # Backward pass\n            loss.backward()\n\n            # SGD parameter update\n            with torch.no_grad():\n                conv_w -= learning_rate * conv_w.grad\n                conv_b -= learning_rate * conv_b.grad\n                dense_w -= learning_rate * dense_w.grad\n                dense_b -= learning_rate * dense_b.grad\n\n    # Prepare outputs (convert to numpy). For conv weights, present as (K, K, F) for readability\n    conv_w_np = conv_w.detach().cpu().permute(2, 3, 0).numpy()  # (K, K, F) since in_channels=1\n    conv_b_np = conv_b.detach().cpu().numpy()\n    dense_w_np = dense_w.detach().cpu().numpy()                 # (flat_dim, C)\n    dense_b_np = dense_b.detach().cpu().numpy()                 # (C,)\n\n    return conv_w_np, conv_b_np, dense_w_np, dense_b_np\n\n\ndef solution():\n    # Example usage matching the problem's example shapes\n    np.random.seed(42)\n    X = np.array([[[1, 2, 3],\n                   [4, 5, 6],\n                   [7, 8, 9]]], dtype=np.float32)\n    y = np.array([[1, 0]], dtype=np.float32)  # one-hot for 2 classes\n\n    conv_w, conv_b, dense_w, dense_b = train_simple_cnn_with_backprop(\n        X, y, epochs=1, learning_rate=0.01, kernel_size=3, num_filters=1\n    )\n\n    # Print shapes and parameters to verify\n    print(\"Conv weights shape (K, K, F):\", conv_w.shape)\n    print(\"Conv bias shape (F,):\", conv_b.shape)\n    print(\"Dense weights shape (flat_dim, C):\", dense_w.shape)\n    print(\"Dense bias shape (C,):\", dense_b.shape)\n    return conv_w, conv_b, dense_w, dense_b\n",
  "timeComplexity": "O(N * F * H_out * W_out * K^2 + N * (F * H_out * W_out) * C)",
  "spaceComplexity": "O(F * K^2 + F * H_out * W_out + (F * H_out * W_out) * C)",
  "platform": "deepml"
};
