import { Problem } from '../../types';

export const DM_58_GAUSSIAN_ELIMINATION_FOR_SOLVING_LINEAR_SYSTEMS: Problem = {
  "id": "dm_58_gaussian_elimination_for_solving_linear_systems",
  "title": "Gaussian Elimination for Solving Linear Systems",
  "difficulty": "Medium",
  "tags": [
    "Linear Algebra",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Task: Implement the Gaussian Elimination Method\n\nImplement a function `gaussian_elimination(A, b)` that performs Gaussian Elimination with partial pivoting to solve the linear system `Ax = b`. The method should first transform the coefficient matrix into an upper triangular form and then use backward substitution to recover the solution vector `x`.\n\nExample:\n\n```\nA = np.array([[2,8,4], [2,5,1], [4,10,-1]], dtype=float)\nb = np.array([2,5,1], dtype=float)\nprint(gaussian_elimination(A, b))\n```\n\nExpected Output:\n\n```\n[11.0, -4.0, 3.0]\n```\n\nReasoning:\nThe Gaussian Elimination method transforms the system of equations into an upper triangular matrix and then uses backward substitution to solve for the variables.",
  "solutionExplanation": "Gaussian elimination solves a linear system by eliminating variables to convert the coefficient matrix into an upper triangular form. At each column i, we select a pivot row with the largest absolute value in that column (partial pivoting) from rows i..n-1, swap it to the current row, and eliminate the entries below the pivot using row operations. This reduces numerical instability and avoids division by very small numbers.\n\nOnce the matrix is upper triangular, the system can be solved with backward substitution: starting from the last equation, we solve for the corresponding variable and substitute it back into the previous equations. This process yields the solution vector x. The implemented function performs all operations using PyTorch tensors, operates in-place on a working copy of the inputs, checks for singularity (near-zero pivots), and returns the final solution.",
  "solutionCode": "import torch\nimport torch.nn as nn\n\ndef gaussian_elimination(A, b):\n    \"\"\"\n    Solve the linear system Ax = b using Gaussian Elimination with partial pivoting.\n\n    Args:\n        A (torch.Tensor or array-like): Coefficient matrix of shape (n, n).\n        b (torch.Tensor or array-like): Right-hand side vector of shape (n,) or (n, 1).\n\n    Returns:\n        torch.Tensor: Solution vector x of shape (n,), dtype=torch.float64.\n    \"\"\"\n    # Convert inputs to torch tensors with double precision for numerical stability\n    A = torch.as_tensor(A, dtype=torch.float64)\n    b = torch.as_tensor(b, dtype=torch.float64)\n\n    if A.dim() != 2 or A.shape[0] != A.shape[1]:\n        raise ValueError(\"A must be a square matrix of shape (n, n)\")\n\n    n = A.shape[0]\n    if b.numel() != n:\n        raise ValueError(\"b must have length n to match A's dimensions\")\n\n    # Ensure b is a 1D vector\n    b = b.reshape(-1)\n\n    # Work on copies to avoid mutating the inputs\n    U = A.clone()\n    y = b.clone()\n\n    atol = 1e-12\n\n    # Forward elimination with partial pivoting\n    for i in range(n):\n        # Pivot selection: index of max |U[k, i]| for k in [i, n)\n        pivot_rel = torch.argmax(torch.abs(U[i:, i]))\n        pivot_row = i + int(pivot_rel.item())\n\n        # Check for singularity (or near-singularity)\n        if torch.isclose(U[pivot_row, i], torch.tensor(0.0, dtype=U.dtype), atol=atol):\n            raise RuntimeError(\"Matrix is singular or nearly singular; pivot is zero.\")\n\n        # Swap rows if needed\n        if pivot_row != i:\n            U[[i, pivot_row]] = U[[pivot_row, i]]\n            y[[i, pivot_row]] = y[[pivot_row, i]]\n\n        # Eliminate entries below the pivot\n        for j in range(i + 1, n):\n            if U[j, i] != 0:\n                factor = U[j, i] / U[i, i]\n                # Update the row j from column i onward\n                U[j, i:] -= factor * U[i, i:]\n                # Update RHS accordingly\n                y[j] -= factor * y[i]\n\n    # Back substitution to solve Ux = y\n    x = torch.zeros(n, dtype=U.dtype)\n    for i in range(n - 1, -1, -1):\n        if torch.isclose(U[i, i], torch.tensor(0.0, dtype=U.dtype), atol=atol):\n            raise RuntimeError(\"Zero pivot encountered during back substitution.\")\n        if i < n - 1:\n            s = torch.dot(U[i, i + 1:], x[i + 1:])\n        else:\n            s = torch.tensor(0.0, dtype=U.dtype)\n        x[i] = (y[i] - s) / U[i, i]\n\n    return x\n\n\ndef solution():\n    # Example usage matching the problem statement\n    A = torch.tensor([[2.0, 8.0, 4.0],\n                      [2.0, 5.0, 1.0],\n                      [4.0, 10.0, -1.0]], dtype=torch.float64)\n    b = torch.tensor([2.0, 5.0, 1.0], dtype=torch.float64)\n\n    x = gaussian_elimination(A, b)\n    # Print as Python list for readability\n    print([float(v) for v in x])\n    return x\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(n^3)",
  "spaceComplexity": "O(n^2)",
  "platform": "deepml"
};
