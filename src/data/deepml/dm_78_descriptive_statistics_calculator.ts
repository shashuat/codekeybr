import { Problem } from '../../types';

export const DM_78_DESCRIPTIVE_STATISTICS_CALCULATOR: Problem = {
  "id": "dm_78_descriptive_statistics_calculator",
  "title": "Descriptive Statistics Calculator",
  "difficulty": "Easy",
  "tags": [
    "Probability"
  ],
  "descriptionMarkdown": "Write a Python function to calculate various descriptive statistics metrics for a given dataset. The function should take a list or NumPy array of numerical values and return a dictionary containing:\n\n- mean: Average of all values\n- median: Middle value when sorted\n- mode: Most frequently occurring value\n- variance: Population variance (divide by N)\n- standard_deviation: Square root of variance\n- 25th_percentile, 50th_percentile, 75th_percentile: Quartile values\n- interquartile_range: Difference between 75th and 25th percentiles (IQR)\n\nExample:\n\nInput:\n[1, 2, 2, 3, 4, 4, 4, 5]\n\nOutput:\n{'mean': 3.125, 'median': 3.5, 'mode': 4, 'variance': 1.6094, 'standard_deviation': 1.2686, ...}\n\nMean is the average of the values. Median is the middle value when sorted (or the average of the two middle values for even-sized datasets). Mode is the most frequent value. Variance and standard deviation measure dispersion, and percentiles split the sorted data into quarters; the IQR is the range between the 75th and 25th percentiles.",
  "solutionExplanation": "We can compute all requested statistics efficiently using vectorized PyTorch tensor operations. First, convert the input data (list or NumPy array) into a 1D float tensor. The mean is obtained via torch.mean. For population variance, we set correction=0 in torch.var, and the standard deviation is the square root of that variance. Quartiles (25th, 50th, 75th percentiles) are computed using torch.quantile with linear interpolation, which matches standard statistical definitions. The median equals the 50th percentile but we compute it explicitly for clarity.\n\nTo find the mode, we use torch.unique with return_counts=True, which yields unique values and their counts. Taking argmax over the counts gives the most frequent value. If multiple values tie for the highest frequency, torch.unique returns sorted unique values, so selecting the first maximum yields the smallest mode among ties, a reasonable and deterministic convention.\n\nThe overall approach is numerically stable (using float64) and leverages PyTorch's vectorized operations for clarity and performance. The function returns a dictionary with all required metrics, and it raises an error for empty inputs.",
  "solutionCode": "import torch\nfrom typing import Any, Dict, Iterable\n\n\ndef descriptive_statistics(data: Iterable[float]) -> Dict[str, Any]:\n    \"\"\"\n    Calculate descriptive statistics for a 1D dataset.\n\n    Args:\n        data: A list-like or NumPy array of numerical values.\n\n    Returns:\n        A dictionary with keys: mean, median, mode, variance, standard_deviation,\n        25th_percentile, 50th_percentile, 75th_percentile, interquartile_range.\n\n    Notes:\n        - Population variance is used (divide by N, i.e., correction=0).\n        - If multiple modes exist, the smallest value among them is returned.\n    \"\"\"\n    # Convert input to a 1D float64 tensor for numerical stability\n    x = torch.as_tensor(data, dtype=torch.float64).flatten()\n\n    if x.numel() == 0:\n        raise ValueError(\"Input data must be non-empty.\")\n\n    # Basic moments\n    mean_val = torch.mean(x)\n    var_val = torch.var(x, correction=0)\n    std_val = torch.sqrt(var_val)\n\n    # Median (explicitly handle even/odd lengths via sorting for clarity)\n    xs, _ = torch.sort(x)\n    n = xs.numel()\n    if n % 2 == 1:\n        median_val = xs[n // 2]\n    else:\n        median_val = 0.5 * (xs[n // 2 - 1] + xs[n // 2])\n\n    # Mode via unique counts (deterministic: smallest among ties)\n    uniques, counts = torch.unique(x, sorted=True, return_counts=True)\n    mode_idx = torch.argmax(counts)\n    mode_val = uniques[mode_idx]\n\n    # Percentiles (quartiles) using linear interpolation\n    q = torch.tensor([0.25, 0.50, 0.75], dtype=torch.float64)\n    quartiles = torch.quantile(x, q, interpolation='linear')\n    p25, p50, p75 = quartiles[0], quartiles[1], quartiles[2]\n    iqr = p75 - p25\n\n    return {\n        'mean': float(mean_val.item()),\n        'median': float(median_val.item()),\n        'mode': float(mode_val.item()),\n        'variance': float(var_val.item()),\n        'standard_deviation': float(std_val.item()),\n        '25th_percentile': float(p25.item()),\n        '50th_percentile': float(p50.item()),\n        '75th_percentile': float(p75.item()),\n        'interquartile_range': float(iqr.item()),\n    }\n\n\nif __name__ == \"__main__\":\n    data = [1, 2, 2, 3, 4, 4, 4, 5]\n    stats = descriptive_statistics(data)\n    print(stats)\n",
  "timeComplexity": "O(N log N) due to sorting/unique for mode and median; other operations are O(N)",
  "spaceComplexity": "O(N) for storing sorted values and unique counts",
  "platform": "deepml"
};
