import { Problem } from '../../types';

export const DM_1_MATRIX_VECTOR_DOT_PRODUCT: Problem = {
  "id": "dm_1_matrix_vector_dot_product",
  "title": "Matrix-Vector Dot Product",
  "difficulty": "Easy",
  "tags": [
    "Linear Algebra",
    "Matrix Operations"
  ],
  "descriptionMarkdown": "Write a Python function that computes the dot product of a matrix and a vector. The function should return a list representing the resulting vector if the operation is valid, or -1 if the matrix and vector dimensions are incompatible.\n\nA matrix (a list of lists) can be dotted with a vector (a list) only if the number of columns in the matrix equals the length of the vector. For example, an n \u00d7 m matrix requires a vector of length m.\n\nExample:\n- Input: a = [[1, 2], [2, 4]], b = [1, 2]\n- Output: [5, 10]\n- Reasoning:\n  - Row 1: (1 \u00d7 1) + (2 \u00d7 2) = 1 + 4 = 5\n  - Row 2: (2 \u00d7 1) + (4 \u00d7 2) = 2 + 8 = 10",
  "solutionExplanation": "To compute a matrix-vector dot product, each element of the output vector is the dot product between one row of the matrix and the input vector. This operation is valid only when the number of columns of the matrix matches the length of the vector. If the dimensions do not align, the operation is undefined and we should return -1.\n\nUsing PyTorch, we convert the Python lists to tensors and perform the multiplication with torch.mv (matrix-vector multiplication). Before that, we validate the input: ensure the matrix is rectangular (all rows have the same length), and that the vector's length matches the matrix's column count. For robustness, we detect whether inputs contain floats and select an appropriate tensor dtype so that outputs preserve integer results when possible and use floating-point when necessary.",
  "solutionCode": "import torch\nimport torch.nn as nn\nfrom typing import List, Union\n\nNumber = Union[int, float]\n\n\ndef matrix_dot_vector(a: List[List[Number]], b: List[Number]) -> Union[List[Number], int]:\n    \"\"\"Compute the dot product of matrix 'a' (n x m) and vector 'b' (m,).\n\n    Returns:\n        - List of length n containing the result of A @ b if dimensions are valid.\n        - -1 if inputs are invalid or dimensions are incompatible.\n    \"\"\"\n    # Basic type checks\n    if not isinstance(a, list) or not isinstance(b, list):\n        return -1\n\n    # Handle empty matrix case explicitly\n    if len(a) == 0:\n        # Interpret as a 0 x 0 matrix to be consistent; only valid if b is length 0\n        return [] if len(b) == 0 else -1\n\n    # Ensure matrix is a list of lists and rectangular\n    if not all(isinstance(row, list) for row in a):\n        return -1\n    m = len(a[0])\n    if not all(len(row) == m for row in a):  # rectangular matrix check\n        return -1\n\n    # Dimension compatibility: columns in 'a' must equal length of 'b'\n    if len(b) != m:\n        return -1\n\n    # Determine dtype: use float if any float present, else int64\n    def _has_float(vals):\n        return any(isinstance(x, float) for x in vals)\n\n    has_float = any(_has_float(row) for row in a) or _has_float(b)\n    dtype = torch.float32 if has_float else torch.int64\n\n    try:\n        A = torch.tensor(a, dtype=dtype)\n        v = torch.tensor(b, dtype=dtype)\n    except Exception:\n        # Non-numeric entries or ragged lists would land here\n        return -1\n\n    # Compute matrix-vector product: result shape (n,)\n    try:\n        result = torch.mv(A, v)\n    except RuntimeError:\n        # Safety net if shapes are somehow invalid at tensor level\n        return -1\n\n    return result.tolist()\n\n\ndef solution() -> None:\n    # Example usage\n    a = [[1, 2], [2, 4]]\n    b = [1, 2]\n    out = matrix_dot_vector(a, b)\n    print(out)  # Expected: [5, 10]\n\n\nif __name__ == \"__main__\":\n    solution()\n",
  "timeComplexity": "O(n*m)",
  "spaceComplexity": "O(n)",
  "platform": "deepml"
};
