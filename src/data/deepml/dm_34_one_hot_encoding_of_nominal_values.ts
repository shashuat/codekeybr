import { Problem } from '../../types';

export const DM_34_ONE_HOT_ENCODING_OF_NOMINAL_VALUES: Problem = {
  "id": "dm_34_one_hot_encoding_of_nominal_values",
  "title": "One-Hot Encoding of Nominal Values",
  "difficulty": "Easy",
  "tags": [
    "Matrix Operations",
    "Embeddings"
  ],
  "descriptionMarkdown": "Write a Python function to perform one-hot encoding of nominal values. The function should take in a 1D numpy array `x` of integer values and an optional integer `n_col` representing the number of columns (classes) for the one-hot encoded array. If `n_col` is not provided, it should be automatically determined from the input array as `max(x) + 1`.\n\nExample:\n\nInput:\n- `x = np.array([0, 1, 2, 1, 0])`\n- `output = to_categorical(x)`\n\nOutput:\n- `[[1. 0. 0.], [0. 1. 0.], [0. 0. 1.], [0. 1. 0.], [1. 0. 0.]]`\n\nEach element in the input array is transformed into a one-hot encoded vector, where the index corresponding to the value in the input array is set to 1, and all other indices are set to 0.",
  "solutionExplanation": "One-hot encoding maps each nominal (categorical) integer index to a vector of length equal to the number of classes, with a single 1 at the position of the class and 0 elsewhere. This representation is commonly used in machine learning pipelines and neural networks as a simple, lossless way to represent categorical variables.\n\nIn PyTorch, we can implement this efficiently using `torch.nn.functional.one_hot`. The input must be a 1D tensor of dtype `long` (integer indices). If `n_col` (the number of classes) is not provided, we infer it from the data as `max(x) + 1`. We include input validation to ensure the array is 1D, contains non-negative integers, and that `n_col` (if provided) is large enough to cover the maximum index in `x`. The resulting one-hot tensor is returned as `float32`, which is often preferred in downstream neural network computations.",
  "solutionCode": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\ndef to_categorical(x, n_col=None):\n    \"\"\"\n    One-hot encode a 1D array of integer indices using PyTorch.\n\n    Args:\n        x (array-like): 1D numpy array or PyTorch tensor of non-negative integer indices.\n        n_col (int, optional): Number of classes (columns). If None, inferred as max(x)+1.\n\n    Returns:\n        torch.Tensor: One-hot encoded tensor of shape (N, n_col) with dtype float32.\n    \"\"\"\n    # Convert input to a 1D tensor\n    t = torch.as_tensor(x)\n    if t.ndim != 1:\n        raise ValueError(\"Input x must be a 1D array or tensor.\")\n\n    # Ensure integer dtype\n    if torch.is_floating_point(t):\n        # Guard against non-integer floats\n        if not torch.all(t == t.round()):\n            raise ValueError(\"Input x must contain integer indices.\")\n        t = t.long()\n    else:\n        t = t.long()\n\n    # Handle empty input edge-case\n    if t.numel() == 0 and n_col is None:\n        raise ValueError(\"n_col must be provided when x is empty.\")\n\n    # Determine number of classes\n    if n_col is None:\n        max_val = int(t.max().item()) if t.numel() > 0 else -1\n        if max_val < -1:\n            raise ValueError(\"Invalid maximum value in x.\")\n        num_classes = max_val + 1\n    else:\n        num_classes = int(n_col)\n        if num_classes <= 0:\n            raise ValueError(\"n_col must be a positive integer.\")\n\n    # Validate indices\n    if t.numel() > 0:\n        if torch.any(t < 0):\n            raise ValueError(\"x must contain non-negative integer indices.\")\n        if num_classes <= int(t.max().item()):\n            raise ValueError(\"n_col must be greater than the maximum index in x.\")\n\n    # One-hot encode and return as float32\n    one_hot = F.one_hot(t, num_classes=num_classes).to(torch.float32)\n    return one_hot\n\n\ndef solution():\n    # Example usage\n    import numpy as np\n    x = np.array([0, 1, 2, 1, 0])\n    output = to_categorical(x)\n    print(output)\n    # tensor([[1., 0., 0.],\n    #         [0., 1., 0.],\n    #         [0., 0., 1.],\n    #         [0., 1., 0.],\n    #         [1., 0., 0.]])\n    return output\n",
  "timeComplexity": "O(N * K)",
  "spaceComplexity": "O(N * K)",
  "platform": "deepml"
};
